---
title: "The process"
author: "Janani Ravi, Samuel Z Chen"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
    depth: 4
    number_sections: false
    theme: united
---
## Environment & Setup
```{r setup, eval=T, results='hide', message=FALSE}
knitr::opts_knit$set(root.dir=rprojroot::find_rstudio_root_file())
# removed setwd option; homedir of *.Rproj is the correct working dir.
# 
# knitr::purl("docs/the_process.Rmd", "scripts/the_process_20190814.Rmd", documentation = 2)
# infile <- "the_process.Rmd"; inpath <- "docs/"; outpath <- "scripts/"
# name <- strsplit(infile, split = "\\.")[[1]][1]
# knitr::purl(paste0(inpath, infile),
#             paste0(outpath, name,
#                    "_rmd2r_", format(Sys.time(), "%Y%m%d"),
#                    ".R", sep = ""),
#             documentation = 2)
```

```{r load, eval=T, results='hide', message=FALSE}
library(here)
library(tidyverse)
library(rmarkdown); library(knitr)
library(wordcloud); library(RColorBrewer)
# ADD OTHER DEPENDENCIES

here::here() # checking to see if the homedir location is accurate

# Sourcing scripts containing package functions
#paste0("R/", list.files("../R/")) %>%
#  purrr::map(source)

##! problem with path? Should start with the-approach, but starts with docs.
## adding path explicitly paste0(path, "/R/") doesn't seem to help either.
for (i in list.files("R/")){
   #print(here::here())
   print(i)
   if(i == "201906data.R") next
   source("R/",i)
 }
# Avoiding conflicts!
conflicted::conflict_prefer("filter", "dplyr")
conflicted::conflict_prefer("Position", "ggplot2")
conflicted::conflict_prefer("as_data_frame", "tibble")
conflicted::conflict_prefer("strsplit", "base")
```

### Cluster files `op_ins_cls` â€”> `tsv`
Run this chunk only if you do not have 'all.txt'
```{r clust_clean_combine, eval=T, results='hide', message=F}

# Initialize dataframe for the combined dataset; Will serve for even 1.
all <- data.frame(matrix(ncol=11, nrow=0))
colnames(all) <- colnames.op_ins_cls

for(x in list.files("data/rawdata_opinscls")){
  print(x)
  inpath <- paste0("data/rawdata_opinscls/", x)
  prot_name <- str_remove(x, ".op_ins_cls")
  # clean_clust_file(path, writepath=NULL, query)
  prot_opinscls <- clean_clust_file(path=inpath, query=prot_name)
  
  all <- bind_rows(all, prot_opinscls)
  # comment next lines to avoid overwriting each time!
  # Last written: Aug 20, 2019
  # write_tsv(prot_opinscls,
  #           path=paste0("data/rawdata_tsv/", prot_name, ".txt"),
  #           col_names=T)
}

# Appending genome-specific signature columns.
# Reading TaxIDs
all_taxid <- read_tsv("data/acc_files/all.taxid", col_names=F)
colnames(all_taxid) <- c("AccNum", "TaxID", "Species.q")
# Reading GCA numbers
all_gca <- read_tsv("data/acc_files/all.gca", col_names=F)
colnames(all_gca) <- c("AccNum", "GCA_ID")
# Adding TaxIDs and GCA_IDs to combined "all" dataframe
all <- all %>%
  left_join(all_taxid, by="AccNum") %>%
  left_join(all_gca, by="AccNum")
# Rearrange columns for easy readability
all <- all %>%
  select(AccNum, Query, ClustID, ClustName,
         DomArch.orig, GenContext.orig,
         Lineage, Species.q, TaxID, GCA_ID,
         arch.PFAM, arch.TMSIG,
         Length, GenName,
         Species.orig, Annotation, GI)

# Write the new combined file; Comment next line(s) to avoid overwriting each time!
# Last written: Aug 20, 2019
# write_tsv(all, path="data/rawdata_tsv/all_raw.txt", col_names=T)
```


## Data import
```{r import, eval=T, results='hide', message=F}
# Example import files: individual or combined ones, pspa.txt, all_raw.txt
#prot <- read_delim("data/rawdata_tsv/all_raw_notax.txt",
#                   delim="\t", col_names=T, trim_ws=T,
#                   escape_double=FALSE, na="NA")

prot <- read_tsv("data/rawdata_opinscls/all.op_ins_cls.clus2table",
                 col_names = c("AccNum", "ClustID", "ClustName.orig",
                               "GenContext.orig", "DomArch.Pfam", "DomArch.orig",
                               "-", "Length", "GeneName",
                               "Lineage", "Species.orig", "GCA_ID",
                               "Annotation", "GI")) %>%
  select(-"-", -GI, -Annotation)

lineages_map <- read_delim("data/acc_files/organisms2lineages_map_bae_20170828.txt",
                           delim="\t", col_names=T, trim_ws=T)

domains_rename <- read_delim("data/acc_files/domains_rename.txt",
                              delim="\t", col_names=TRUE)

# domains_ignore <- read_delim("data/acc_files/domains_ignore.txt",
#                              delim="\t", col_names=T)

domains_keep <- read_delim("data/acc_files/domains_keep.txt",
                            delim="\t", col_names=T)

query_domains <- read_delim("data/acc_files/query_domains.txt",
                            delim="\t", col_names=T)
```

## Cleanup
### DomArch cleanup & Reversal of operons
```{r cleanup, eval=T, results='hide', message=F,warning=FALSE}
# Cleanup Clusters
# Remove tails (singletons)?
prot <- prot %>%
  cleanup_clust(repeat2s = TRUE, domains_keep, domains_rename)

# Cleanup Species
prot <- prot %>%
  cleanup_species(remove_empty = FALSE)

# Cleanup GenContext
# Calls reverse_operons
prot <- prot %>%
  cleanup_gencontext(repeat2s = TRUE, remove_empty = FALSE, domains_rename) 

prot <- prot %>%
  cleanup_domarch(repeat2s = TRUE, domains_rename)

prot <- prot %>%
  remove_tails()

```

## Data analysis
### Select columns for data export
```{r select-cols, eval=T}
prot_data <- prot %>%
  select(AccNum, Species, Lineage,
         DomArch, GenContext,
         Length, GeneName, GCA_ID)
```

### Viewing your data
```{r view-data, eval=T}
paged_table(prot_data)
```

### Wordcounts
```{r wordcounts, eval=T}
## Counts of domains in XXX domain architectures

##### Obsolete Now: word counts now handled in upset/wordcloud functions #####

## minimal functions may be able to removed and put within other summarize/ plotting functions
DA.doms.wc <- prot %>% elements2words(column = "DomArch", conversion_type = "da2doms") %>%
  words2wc()
DA.doms.wc %>%
  head() %>%
  kable()
# DA.doms.wc.ge5 <- filter.freq(DA.doms.wc, 5)
## Counts of domain architectures in the GenContext of XXX homologs
GC.DA.wc <- prot %>% elements2words(column = "GenContext", conversion_type = "gc2da") %>%
  words2wc()
GC.DA.wc %>%
  head() %>%
  kable()
```

### UpSet plots
```{r upset-plot-da, eval=T, out.height="300px"}
# Per
pspa <- prot %>% filter(grepl("pspa|snf7",ignore.case = T,ClustName))
upset.plot(pspa, 30, "da2doms")
```

```{r upset-plot-gc, eval=T, out.height="600px"}
upset.plot(pspa, 100, "gc2da")
```

### Worclouds
```{r , eval= TRUE, out.height='600px'}
# move to plotting.R and call just the custom function
wordcloud_element("da2doms", pspa, min_freq = 10) 
wordcloud_element("gc2da", pspa, min_freq = 100)
```
### Lineage summaries
```{r lin-summary, eval=T}
## Main Domain Architectures -- Counts by DA and Lineage
prot.DA.summ.byLin <- summ.DA.byLin(prot)
prot.DA.summ <- summ.DA(prot.DA.summ.byLin)

prot.DA.summ.byLin %>% head() %>% kable()
prot.DA.summ %>% head() %>% kable()

## Main Genomic Contexts -- Summarized by DA & Lineage
prot.GC.summ.byDALin <- summ.GC.byDALin(prot)
prot.GC.summ.byLin <- summ.GC.byLin(prot)
prot.GC.summ <- summ.GC(prot.GC.summ.byDALin)

prot.GC.summ.byDALin %>% head() %>% kable()
prot.GC.summ.byLin %>% head() %>% kable()
prot.GC.summ %>% head() %>% kable()
```
### Paralog Table
```{r paralog table, eval=T, message=FALSE, results='hide'}
# Use prot with Query column
paralogs <- find_paralogs(pspa) %>%
  head() %>%
  kable()
```

### Total Counts
```{r total counts, eval=T, message=FALSE, results='hide'}
DA.cumulative <- total_counts(pspa,
                              cutoff =0, type="DA")
DA.cumulative %>%
  head() %>%
  kable()

GC.cumulative <- total_counts(pspa,
                              cutoff=50, type="GC") 
GC.cumulative %>%
  head() %>%
  kable()
```
### Lineage summary plots
```{r lin-summ-plot, eval=T, out.width='70%'}

# now calculates and filters by totalcounts within function

lineage.DA.plot(pspa, 
                colname = "DomArch", type = "da2doms", cutoff = 200)

lineage.DA.plot(pspa,
                "GenContext", type = "gc2da", cutoff = 100)
```


```{r network-plot, eval=T, out.width='70%'}
#liai_liaf <- prot %>% filter(grepl("liai-liaf",ignore.case = T, ClustName))
#pspb <- prot %>% filter(grepl("pspb",ignore.case = T, ClustName))

#pspa_only <- prot %>% filter(grepl("pspa",ignore.case = T, ClustName))
#snf7 <- prot %>% filter(grepl("snf7",ignore.case = T, ClustName))
domain_network(pspa, "DomArch",domains_of_interest = "", cutoff_type = "Lineage", 2, "circle")

### ADD filters,
### Add params layout

```




### Add Leaves
```{r add-leaves, eval=T}
add_leaves(input_file ="data/rawdata_aln/pspa_snf7.gismo.aln",
           lin = pspa,
           reduced=TRUE)
```

### Generate MSA + Phylogenetic tree
```{r msa-tree,echo=FALSE,results='hide',fig.keep='all',  out.width="50%",out.height="50%"}
# Create a fasta file
convert_aln2fa(input_file= "data/rawdata_aln/pspa_snf7.gismo.aln",
               lin = pspa,0
               #lin_file="data/pspa_snf7.txt",
               output_path="data/alignments/pspa.fasta",
               reduced=TRUE) %>% head()
# Texi2pdf outputs its files in current working directory, not where the file is
msa_pdf("data/alignments/pspa.fasta", output_path = NULL)
#pdf_convert(pdf="data/alignments/pspa.fasta.pdf")
pdf_convert(pdf ="data/alignments/pspa.fasta.pdf")

files <- list.files(getwd(), pattern ="^pspa.fasta(.*).png$")
include_graphics(files)

#pdf(files)

file.remove(files)

#pdf2image then render image here?
#should I be deleting images
seq_tree("data/alignments/pspa.fasta")

```




