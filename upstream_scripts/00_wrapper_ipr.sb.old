#!/bin/bash

# MolEvolvR: Companion wrapper script
# accnum –> fasta –> deltablast -> edirect -> blastclust -> iprscan/rpsblast -> cleanup w/ lineages!
# To run on compute.cvm.msu.edu

# Created: 2020.07.09
# Last modified: 2020.12.14
# Authors: Lauren Sosinski, Janani Ravi
# On GitHub: currently in jravilab/molevol_scripts/upstream_scripts

# Input type: text file containing paths to iprscan files to analyze

############
## TORQUE ##
############
#PBS -l walltime=04:30:00       # time limit; RESET, if you need longer time
#PBS -l nodes=1:ppn=10          # number of nodes requested
#PBS -N molevol_analysis        # name of job being run

## change output directory based on user input
OUTPATH=$SLURM_SUBMIT_DIR
cd ${OUTPATH}

## USER INPUTS
INFILEPATHS_LIST=$1

## USAGE
## qsub /data/research/jravilab/molevol_scripts/upstream_scripts/00_wrapper_ipr.sb -F /path/to/input.txt

# Location of databases/dependencies 
export INTERPRO=/opt/software/iprscan/5.47.82.0-Python3/data:/data/common_data/iprscan:$INTERPRO
export NCBI_API_KEY=YOUR_KEY_HERE

## Create logfile w/ column names
printf "\nSTART\tSTOP\tquery\tacc2info\tipr2da\tipr2lin\ttotal_time" >> ${OUTPATH}/logfile.txt

#####################
## LOADING MODULES ##
#####################

# Prevent "module: command not found"
# Read more about it https://www.sdsc.edu/support/user_guides/tscc.html
source /etc/profile.d/modules.sh

module purge                                    ## clear loaded modules
module load R                                   ## load R
module load edirect                             ## load edirect
module load BLAST                               ## load blast (for blastclust)
module load BLAST+ BioPerl                      ## load blast+
module load iprscan                             ## load iprscan

start=$SECONDS                                  ## get current time
START_DT=$(date '+%d/%m/%Y-%H:%M:%S')

FILES=$(cat ${INFILEPATHS_LIST})                        ## list of files (with paths) to be processed
#total=$(( ((3*60)+50)*60 ))                    ## total time the job can take in seconds, this should match your SBATCH line above
#maxtime=$(( 120*60 ))                          ## maximum time to process one input, need to do some experimenting with your inputs

for FILE in $(shuf -e ${FILES[@]})
do
   F=$(basename ${FILE})
   PREFIX=$(echo "${F%%.*}")                    ## takes PREFIX of file
   OUTDIR=${OUTPATH}/${PREFIX}_ipr      ## variable containing output filepath based PREFIX
   printf "${PREFIX}"

   if [ ! -d ${OUTDIR} ]; then                  ## if the output directory doesn't exist
      mkdir ${OUTDIR}                           ## make the directory
      cd ${OUTDIR}

      ## ACC2INFO ##
      acc2info_start=$SECONDS
      cat ${FILE} | awk -F "\t" '{ print $1 }' | sort -u > ${OUTDIR}/${PREFIX}.all_accnums.txt
      sh /data/research/jravilab/molevol_scripts/upstream_scripts/acc2info.sh ${OUTDIR}/${PREFIX}.all_accnums.txt ${PREFIX} ${OUTDIR}
      acc2info_dur=$(( $SECONDS - $acc2info_start ))

      ## IPR2LIN ##
      ipr2lin_start=$SECONDS
      Rscript /data/research/jravilab/molevol_scripts/upstream_scripts/01.4_ipr2lin.R ${FILE} ${OUTDIR}/${PREFIX}.acc2info.tsv ${PREFIX}
      ipr2lin_duration=$(( $SECONDS -  $ipr2lin_start ))
      
      ## IPR2DA ##
      ipr2da_start=$SECONDS
      Rscript /data/research/jravilab/molevol_scripts/upstream_scripts/05a_ipr2da.R ${FILE} ${OUTDIR}/${PREFIX}.acc2info.tsv ${PREFIX}
      ipr2da_duration=$(( $SECONDS - $ipr2da_start ))
				          
      ## Figure out how long the entire script took to run
      duration=$(( $SECONDS - $start ))
      printf "\nTotal run time: $duration\n"
      STOP_DT=$(date '+%d/%m/%Y-%H:%M:%S')

      ## Add benchmarking times to logfile
      printf "\n${START_DT}\t${STOP_DT}\t${PREFIX}\t${acc2info_dur}\t${ipr2lin_duration}\t${ipr2da_duration}\t${duration}" >> ${OUTPATH}/logfile.txt
   
   fi
done

# FA: disabled b/c docker's handling perms
# setfacl -R -m group:shiny:r-x ${OUTDIR}
